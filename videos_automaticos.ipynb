{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O-ioqfcBwM-"
      },
      "source": [
        "# GENERACION DEL TEXTO ALINEADO AL TIEMPO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjLJ6mHptbIx"
      },
      "source": [
        "# üìé Documentation\n",
        "\n",
        "* `input_format`: The source of the audio/video file to be transcribed\n",
        "  * `youtube`: A YouTube video\n",
        "    * The transcribed file(s) are saved to this Colab, and will be deleted when the Colab runtime is disconnected.\n",
        "  * `gdrive`: A file in your Google Drive account\n",
        "    * If you select this option, you will need to allow this notebook to connect to your Google Drive account.\n",
        "    * The transcribed file(s) are saved to the same folder as the original file.\n",
        "  * `local`: A local file that you have uploaded to this Colab\n",
        "    * If you select this option, you will need to first upload the file to the Files tab (see Step 1 [here](https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozMzc1MzU3)).\n",
        "    * The transcribed file(s) are saved to this Colab, and will be deleted when the Colab runtime is disconnected.\n",
        "* `file`: The URL of the YouTube video or the path of the audio file to be transcribed.\n",
        "  * Example: `file = \"https://www.youtube.com/watch?v=AUDIO\"` (transcribing a YouTube video)\n",
        "  * Example: `file = \"/content/drive/My Drive/AUDIO.mp3\"` (transcribing a Google Drive file)\n",
        "  * Example: `file = \"/content/AUDIO.mp3\"` (transcribing a local file)\n",
        "* `plain`: Whether to save the transcription as a text file or not.\n",
        "* `srt`: Whether to save the transcription as an SRT file or not.\n",
        "* `vtt`: Whether to save the transcription as a VTT file or not.\n",
        "* `tsv`: Whether to save the transcription as a TSV (tab-separated values) file or not.\n",
        "* `download`: Whether to download the transcribed file(s) or not.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuR-jeyP-An8"
      },
      "source": [
        "# ‚ú® README\n",
        "\n",
        "This is the companion Colab for the article \"[How to transcribe your audio to text, for free (with SRTs/VTTs!)](https://wandb.ai/wandb_fc/gentle-intros/reports/How-to-transcribe-your-audio-to-text-for-free-with-SRTs-VTTs---VmlldzozNDczNTI0)\".\n",
        "\n",
        "This Colab shows how to use OpenAI's Whisper to transcribe audio and audiovisual files, and how to save that transcription as a plain text file or as a VTT/SRT caption file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1HgdH9iHf2M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAQKStuINe3G"
      },
      "outputs": [],
      "source": [
        "# @title üå¥ Change the values in this section\n",
        "\n",
        "# @markdown Select the source of the audio/video file to be transcribed\n",
        "input_format = \"youtube\" #@param [\"youtube\", \"gdrive\", \"local\"]\n",
        "\n",
        "# @markdown Enter the URL of the YouTube video or the path of the audio file to be transcribed\n",
        "file = \"https://www.youtube.com/watch?v=iFl2_XlSvX4\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as text file\n",
        "plain = True #@param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Click here if you'd like to save the transcription as an SRT file\n",
        "srt = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as a VTT file\n",
        "vtt = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to save the transcription as a TSV file\n",
        "tsv = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Click here if you'd like to download the transcribed file(s) locally\n",
        "\n",
        "download = False #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLoNmM0sKyIf"
      },
      "source": [
        "# üõ† Set Up\n",
        "\n",
        "The blocks below install all of the necessary Python libraries (including Whisper), configures Whisper, and contains code for various helper functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfnRc8yPM79j"
      },
      "source": [
        "## ü§ù Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bF1enPzG-qKE",
        "outputId": "0e563783-5fdc-45fe-af34-fa5ac0987f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: html2image in /usr/local/lib/python3.11/dist-packages (2.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from html2image) (2.32.3)\n",
            "Requirement already satisfied: websocket-client==1.* in /usr/local/lib/python3.11/dist-packages (from html2image) (1.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->html2image) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->html2image) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->html2image) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->html2image) (2025.1.31)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,607 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,696 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,244 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,844 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,848 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,118 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,543 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [47.1 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,154 kB]\n",
            "Fetched 26.5 MB in 3s (10.3 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 libudev1 snapd squashfs-tools\n",
            "  systemd-hwe-hwdb udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 snapd\n",
            "  squashfs-tools systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 8 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 30.3 MB of archives.\n",
            "After this operation, 123 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.15 [76.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.15 [1,557 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.67.1+22.04 [27.8 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 30.3 MB in 3s (11.7 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 126333 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.15_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.15) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.15) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 126533 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.15_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.15) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.67.1+22.04_amd64.deb ...\n",
            "Unpacking snapd (2.67.1+22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service ‚Üí /lib/systemd/system/apparmor.service.\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.15) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.67.1+22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service ‚Üí /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service ‚Üí /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service ‚Üí /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service ‚Üí /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service ‚Üí /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service ‚Üí /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service ‚Üí /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer ‚Üí /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket ‚Üí /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service ‚Üí /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 126762 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.15) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ],
      "source": [
        "# Dependencies\n",
        "\n",
        "!pip install -q yt-dlp\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q git+https://github.com/m-bain/whisperx.git\n",
        "!pip install silero-vad pydub torch --quiet\n",
        "\n",
        "!pip install html2image\n",
        "import os, re\n",
        "import torch\n",
        "from pathlib import Path\n",
        "!apt-get update\n",
        "!apt-get install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "\n",
        "\n",
        "import whisper\n",
        "from whisper.utils import get_writer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4eLQzNOo5_r"
      },
      "source": [
        "## üëã Whisper configuration\n",
        "\n",
        "This Colab use `large`, [the medium-sized, English-only](https://github.com/openai/whisper#available-models-and-languages) Whisper model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCNc3EfV4EIt",
        "outputId": "5feb43ae-2356-4a8a-dd9d-69d60631d736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.88G/2.88G [00:38<00:00, 79.8MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# Use CUDA, if available\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load the desired model\n",
        "model = whisper.load_model(\"large\").to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvN1wRXbo-7C"
      },
      "source": [
        "## üí™ YouTube helper functions\n",
        "\n",
        "Code for helper functions when running Whisper on a YouTube video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLmwvJ3tM-CD"
      },
      "outputs": [],
      "source": [
        "import yt_dlp\n",
        "def to_snake_case(name):\n",
        "    return name.lower().replace(\" \", \"_\").replace(\":\", \"_\").replace(\"__\", \"_\")\n",
        "\n",
        "def download_youtube_audio_yt_dlp(url ,output_path=\"audioL.mp3\"):\n",
        "    ydl_opts = {\n",
        "        'format': 'bestaudio/best',\n",
        "        'outtmpl': output_path.replace(\".mp3\", \"\"),\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "            'preferredquality': '192',\n",
        "        }],\n",
        "\n",
        "\n",
        "        'quiet': True,\n",
        "        'noplaylist': True\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "\n",
        "    return output_path\n",
        "import subprocess\n",
        "\n",
        "def recortar_audio(input_path, output_path, start_time, end_time):\n",
        "    comando = [\n",
        "        \"ffmpeg\",\n",
        "        \"-i\", input_path,\n",
        "        \"-ss\", start_time,\n",
        "        \"-to\", end_time,\n",
        "        \"-c\", \"copy\",\n",
        "        output_path\n",
        "    ]\n",
        "    subprocess.run(comando, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ech5wPCwtO_P"
      },
      "source": [
        "# ‚úç Transcribing with Whisper\n",
        "\n",
        "Ultimately, calling Whisper is as easy as one line!\n",
        "* `result = model.transcribe(file)`\n",
        "\n",
        "The majority of this new `transcribe_file` function is actually just for exporting the results of the transcription as a text, VTT, or SRT file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22CwQZnOtGO1"
      },
      "outputs": [],
      "source": [
        "def transcribe_file(model, file, plain, srt, vtt, tsv, download):\n",
        "    \"\"\"\n",
        "    Runs Whisper on an audio file\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: Whisper\n",
        "        The Whisper model instance.\n",
        "\n",
        "    file: str\n",
        "        The file path of the file to be transcribed.\n",
        "\n",
        "    plain: bool\n",
        "        Whether to save the transcription as a text file or not.\n",
        "\n",
        "    srt: bool\n",
        "        Whether to save the transcription as an SRT file or not.\n",
        "\n",
        "    vtt: bool\n",
        "        Whether to save the transcription as a VTT file or not.\n",
        "\n",
        "    tsv: bool\n",
        "        Whether to save the transcription as a TSV file or not.\n",
        "\n",
        "    download: bool\n",
        "        Whether to download the transcribed file(s) or not.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    A dictionary containing the resulting text (\"text\") and segment-level details (\"segments\"), and\n",
        "    the spoken language (\"language\"), which is detected when `decode_options[\"language\"]` is None.\n",
        "    \"\"\"\n",
        "    file_path = Path(file)\n",
        "    print(f\"Transcribing file: {file_path}\\n\")\n",
        "\n",
        "    output_directory = file_path.parent\n",
        "\n",
        "    # Run Whisper\n",
        "    result = model.transcribe(file, verbose = False, language = \"es\")\n",
        "\n",
        "    if plain:\n",
        "        txt_path = file_path.with_suffix(\".txt\")\n",
        "        print(f\"\\nCreating text file\")\n",
        "\n",
        "        with open(txt_path, \"w\", encoding=\"utf-8\") as txt:\n",
        "            txt.write(result[\"text\"])\n",
        "    if srt:\n",
        "        print(f\"\\nCreating SRT file\")\n",
        "        srt_writer = get_writer(\"srt\", output_directory)\n",
        "        srt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if vtt:\n",
        "        print(f\"\\nCreating VTT file\")\n",
        "        vtt_writer = get_writer(\"vtt\", output_directory)\n",
        "        vtt_writer(result, str(file_path.stem))\n",
        "\n",
        "    if tsv:\n",
        "        print(f\"\\nCreating TSV file\")\n",
        "\n",
        "        tsv_writer = get_writer(\"tsv\", output_directory)\n",
        "        tsv_writer(result, str(file_path.stem))\n",
        "\n",
        "    if download:\n",
        "        from google.colab import files\n",
        "\n",
        "        colab_files = Path(\"/content\")\n",
        "        stem = file_path.stem\n",
        "\n",
        "        for colab_file in colab_files.glob(f\"{stem}*\"):\n",
        "            if colab_file.suffix in [\".txt\", \".srt\", \".vtt\", \".tsv\"]:\n",
        "                print(f\"Downloading {colab_file}\")\n",
        "                files.download(str(colab_file))\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXN4iqYyWDsw"
      },
      "source": [
        "# üßº C√≥digo para eliminar el ruido del audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhMX8vvOWRZ4",
        "outputId": "3f02a940-f5b6-462b-a85d-c317555b008a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        }
      ],
      "source": [
        "# Importar lo necesario\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "import torch\n",
        "\n",
        "# Cargar el modelo Silero VAD y las funciones auxiliares\n",
        "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
        "                              model='silero_vad',\n",
        "                              force_reload=True)\n",
        "\n",
        "# Desempaquetar las funciones necesarias\n",
        "(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils\n",
        "\n",
        "# Ahora puedes usar 'get_speech_timestamps' y 'collect_chunks' en tu c√≥digo\n",
        "\n",
        "\n",
        "def aplicar_vad(input_path=\"audioS.mp3\", output_path=\"audio.mp3\"):\n",
        "    # Cargar el modelo Silero VAD\n",
        "    model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad', force_reload=True)\n",
        "    (get_speech_timestamps, _, read_audio, _, _) = utils\n",
        "\n",
        "    # Leer audio en formato compatible\n",
        "    audio = read_audio(input_path, sampling_rate=16000)\n",
        "\n",
        "    # Obtener los fragmentos con voz\n",
        "    speech_timestamps = get_speech_timestamps(audio, model, sampling_rate=16000)\n",
        "\n",
        "    if len(speech_timestamps) == 0:\n",
        "        print(\"‚ùå No se detect√≥ voz en el audio.\")\n",
        "        return None\n",
        "\n",
        "    # Combinar partes con voz\n",
        "    clean_audio = collect_chunks(speech_timestamps, audio)\n",
        "\n",
        "\n",
        "\n",
        "    # Guardar resultado\n",
        "    import soundfile as sf\n",
        "    sf.write(output_path, clean_audio, 16000)\n",
        "    print(f\"‚úÖ Audio sin silencios guardado en: {output_path}\")\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kf2TkvJsrwR"
      },
      "source": [
        "# Alineacion del texto con el audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "8rYMyVycs44y",
        "outputId": "11d46273-4a97-4c1e-a1e6-87bd7e4780a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import torch\\nimport whisperx\\nimport json\\n\\ndef alinear_con_whisperx(audio_path, transcription_text, idioma=\"es\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\\n    \\n    Alinea la transcripci√≥n con el audio usando WhisperX.\\n\\n    Par√°metros:\\n      audio_path (str): Ruta al archivo de audio (ej. \"audio.mp3\").\\n      transcription_text (str): Texto transcrito previamente (ej. result[\"text\"] de Whisper).\\n      idioma (str): C√≥digo del idioma (por ejemplo, \"es\" para espa√±ol, \"en\" para ingl√©s).\\n      device (str): Dispositivo para ejecutar (\"cuda\" o \"cpu\").\\n\\n    Retorna:\\n      word_segments (list): Lista de diccionarios con la alineaci√≥n de cada palabra,\\n                            cada uno con keys: \\'word\\', \\'start\\', \\'end\\', etc.\\n    \\n    # Cargar el modelo de alineaci√≥n y sus metadatos\\n    model_a, metadata = whisperx.load_align_model(language_code=idioma, device=device)\\n    print(\"Tipo de metadata:\", type(metadata))\\n    print(\"Contenido de metadata:\", metadata)\\n\\n    # Verificamos tipo de transcripci√≥n\\n    if isinstance(transcription_text, str):\\n        transcription_text = [{\"text\": transcription_text}]\\n    # Ejecutar la alineaci√≥n.\\n\\n    alignment_result = whisperx.align(\\n    transcript=transcription_text,\\n    model=model_a,\\n    align_model_metadata=metadata,\\n    audio=audio_path,\\n    device=device,\\n    return_char_alignments=False\\n)\\n\\n\\n\\n    # Obtener los segmentos alineados a nivel de palabra\\n    alineado = alignment_result[\"word_segments\"]\\n\\n     # Guardar el resultado en un archivo JSON\\n    json_path = Path(audio_path).with_suffix(\".aligned.json\")\\n    with open(json_path, \"w\", encoding=\"utf-8\") as f:\\n        json.dump(alineado, f, ensure_ascii=False, indent=4)\\n\\n\\n    print(f\"Alineaci√≥n guardada en: {json_path}\")\\n    # Devuelve la lista de segmentos alineados a nivel de palabra\\n    return alignment_result[\"word_segments\"]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "def alinear_con_whisperx(audio_path, transcription_text, idioma=\"es\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "    import whisperx\n",
        "    import torch\n",
        "    import re\n",
        "    from pathlib import Path\n",
        "    import json\n",
        "\n",
        "    def limpiar_texto_espanol(texto):\n",
        "            texto = re.sub(r\"[^\\w\\s√°√©√≠√≥√∫√º√±√Å√â√ç√ì√ö√ú√ë.,;:¬°!¬ø?\\\"'()\\-\\[\\]{}<>‚Ä¶‚Äì‚Äî¬∞%‚Ç¨$@#&+=*/\\\\]\", \"\", texto)\n",
        "            texto = texto.replace(\":\", \"\")   # Escapar los dos puntos\n",
        "            texto = texto.replace(\"'\", \"\")   # Escapar comillas simples\n",
        "            texto = texto.replace('\"', '')   # Escapar comillas dobles\n",
        "            texto = texto.replace(\"\\\\\", \"\") # Escapar backslashes\n",
        "            return texto\n",
        "\n",
        "    # Si es texto plano, error porque no hay timestamps\n",
        "    if isinstance(transcription_text, str):\n",
        "        raise ValueError(\"Se requiere una transcripci√≥n segmentada con tiempos (start, end) para alinear.\")\n",
        "\n",
        "    # Limpiar el texto de emojis y s√≠mbolos raros\n",
        "    for s in transcription_text:\n",
        "        s[\"text\"] = limpiar_texto_espanol(s[\"text\"])\n",
        "\n",
        "    # Eliminar segmentos vac√≠os\n",
        "    transcription_text = [s for s in transcription_text if s.get(\"text\", \"\").strip()]\n",
        "\n",
        "    # Cargar el modelo de alineaci√≥n\n",
        "    model_a, metadata = whisperx.load_align_model(language_code=idioma, device=device)\n",
        "\n",
        "    # Alinear\n",
        "    alignment_result = whisperx.align(\n",
        "        transcript=transcription_text,\n",
        "        model=model_a,\n",
        "        align_model_metadata=metadata,\n",
        "        audio=audio_path,\n",
        "        device=device,\n",
        "        return_char_alignments=False\n",
        "    )\n",
        "     # Obtener los segmentos alineados a nivel de palabra\n",
        "    alineado = alignment_result[\"word_segments\"]\n",
        "\n",
        "     # Guardar el resultado en un archivo JSON\n",
        "    json_path = Path(audio_path).with_suffix(\".aligned.json\")\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(alineado, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "\n",
        "    print(f\"Alineaci√≥n guardada en: {json_path}\")\n",
        "\n",
        "    return alignment_result[\"word_segments\"]\n",
        "\n",
        "\"\"\"import torch\n",
        "import whisperx\n",
        "import json\n",
        "\n",
        "def alinear_con_whisperx(audio_path, transcription_text, idioma=\"es\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "    \"\"\"\"\"\"\n",
        "    Alinea la transcripci√≥n con el audio usando WhisperX.\n",
        "\n",
        "    Par√°metros:\n",
        "      audio_path (str): Ruta al archivo de audio (ej. \"audio.mp3\").\n",
        "      transcription_text (str): Texto transcrito previamente (ej. result[\"text\"] de Whisper).\n",
        "      idioma (str): C√≥digo del idioma (por ejemplo, \"es\" para espa√±ol, \"en\" para ingl√©s).\n",
        "      device (str): Dispositivo para ejecutar (\"cuda\" o \"cpu\").\n",
        "\n",
        "    Retorna:\n",
        "      word_segments (list): Lista de diccionarios con la alineaci√≥n de cada palabra,\n",
        "                            cada uno con keys: 'word', 'start', 'end', etc.\n",
        "    \"\"\"\"\"\"\n",
        "    # Cargar el modelo de alineaci√≥n y sus metadatos\n",
        "    model_a, metadata = whisperx.load_align_model(language_code=idioma, device=device)\n",
        "    print(\"Tipo de metadata:\", type(metadata))\n",
        "    print(\"Contenido de metadata:\", metadata)\n",
        "\n",
        "    # Verificamos tipo de transcripci√≥n\n",
        "    if isinstance(transcription_text, str):\n",
        "        transcription_text = [{\"text\": transcription_text}]\n",
        "    # Ejecutar la alineaci√≥n.\n",
        "\n",
        "    alignment_result = whisperx.align(\n",
        "    transcript=transcription_text,\n",
        "    model=model_a,\n",
        "    align_model_metadata=metadata,\n",
        "    audio=audio_path,\n",
        "    device=device,\n",
        "    return_char_alignments=False\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "    # Obtener los segmentos alineados a nivel de palabra\n",
        "    alineado = alignment_result[\"word_segments\"]\n",
        "\n",
        "     # Guardar el resultado en un archivo JSON\n",
        "    json_path = Path(audio_path).with_suffix(\".aligned.json\")\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(alineado, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "\n",
        "    print(f\"Alineaci√≥n guardada en: {json_path}\")\n",
        "    # Devuelve la lista de segmentos alineados a nivel de palabra\n",
        "    return alignment_result[\"word_segments\"]\n",
        "\"\"\"\n",
        "# Ejemplo de uso:\n",
        "# Sup√≥n que ya tienes tu transcripci√≥n de Whisper en la variable `result`\n",
        "# transcripcion = result[\"text\"]\n",
        "# word_segments = alinear_con_whisperx(\"audio.mp3\", transcripcion, idioma=\"es\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLC_tpz6tgq6"
      },
      "source": [
        "# üí¨ TRANCRIPCION\n",
        "\n",
        "This block actually calls `transcribe_file` üòâ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cd0xy9xsdWR",
        "outputId": "f58e24dc-c408-4d67-ec02-81d5fdc01491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå No existe: audio.mp3\n",
            "‚ùå No existe: audioL.mp3\n",
            "‚ùå No existe: audio.txt\n",
            "‚ùå No existe: audio.srt\n",
            "‚ùå No existe: salida.mp4\n",
            "‚ùå No existe: audio.aligned.json\n",
            "‚ùå No existe: inputs.txt\n",
            "‚ùå No existe: imagenes_por_frase\n",
            "‚ùå No existe: t\n",
            "‚ùå No existe: tt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Archivos y carpetas a eliminar\n",
        "elementos = [\n",
        "    \"audio.mp3\", \"audioL.mp3\", \"audio.txt\", \"audio.srt\",\n",
        "    \"salida.mp4\", \"audio.aligned.json\", \"inputs.txt\",\n",
        "     \"imagenes_por_frase\",\"t\", \"tt\",  # etc.\n",
        "]\n",
        "\n",
        "for elemento in elementos:\n",
        "    if os.path.exists(elemento):\n",
        "        if os.path.isdir(elemento):\n",
        "            shutil.rmtree(elemento)\n",
        "            print(f\"üßπ Carpeta eliminada: {elemento}\")\n",
        "        else:\n",
        "            os.remove(elemento)\n",
        "            print(f\"‚úÖ Archivo eliminado: {elemento}\")\n",
        "    else:\n",
        "        print(f\"‚ùå No existe: {elemento}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngTGllHutSfo",
        "outputId": "5cf04ac7-e9b9-4ba8-d20c-5900c8a6825c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing file: audio.mp3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3298/3298 [00:06<00:00, 541.62frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating text file\n",
            "\n",
            "Creating SRT file\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if input_format == \"youtube\":\n",
        "    # Download the audio stream of the YouTube video\n",
        "\n",
        "    url = file  # En este caso, `file` es la URL del video\n",
        "    audio = download_youtube_audio_yt_dlp(url)\n",
        "    recortar_audio(\"audioL.mp3\", \"audio.mp3\", \"00:1:40\", \"00:2:13\")\n",
        "    # aplicar_vad(\"audioS.mp3\", \"audio.mp3\") 1:01 : 1:12 ,\n",
        "\n",
        "    # Run Whisper on the audio stream\n",
        "    result = transcribe_file(model, \"audio.mp3\", plain, srt, vtt, tsv, download)\n",
        "elif input_format == \"gdrive\":\n",
        "    # Authorize a connection between Google Drive and Google Colab\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Run Whisper on the specified file\n",
        "    result = transcribe_file(model, file, plain, srt, vtt, tsv, download)\n",
        "elif input_format == \"local\":\n",
        "    # Run Whisper on the specified file\n",
        "    result = transcribe_file(model, file, plain, srt, vtt, tsv, download)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9nMlUWGvFsM"
      },
      "source": [
        "# ALINEALO !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmc5RLci9QYw",
        "outputId": "e89d3601-cd09-40d1-f907-f62a7a2f0a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mucha money, pero los millones no aguantan el llanto De cuando me siento solo en mi cuarto De cuando el balc√≥n no se siente tan alto To' quieren la fama, to' quieren el cuarto Y yo ¬øQu√© cambiar√≠a la gloria y mi riqueza? Solo por saber c√≥mo es que t√∫ vas a Por sacarte un d√≠a de mi casa Ay, ay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n",
            "DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n",
            "Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_voxpopuli_base_10k_asr_es.pt\" to /root/.cache/torch/hub/checkpoints/wav2vec2_voxpopuli_base_10k_asr_es.pt\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 360M/360M [00:04<00:00, 85.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alineaci√≥n guardada en: audio.aligned.json\n"
          ]
        }
      ],
      "source": [
        "transcripcion = result[\"segments\"]  # <-- Esto es una lista de diccionarios ‚úÖ\n",
        "\n",
        "print(result[\"text\"])\n",
        "# Pass the variable transcripcion which contains the transcription text\n",
        "alineado = alinear_con_whisperx(\"audio.mp3\", transcripcion, idioma=\"es\")\n",
        "    # Obtener los segmentos alineados a nivel de palabra\n",
        "    # Guardar como JSON\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYEnui6XCjAP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENERACION DE IMAGENES PRO PARA VIDEOS AUTOMATICOS Y RENDERIZADO !!!!üé¨"
      ],
      "metadata": {
        "id": "ZRPIxJBa_tjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import random\n",
        "\n",
        "\n",
        "def parse_srt_time(timestr):\n",
        "    \"\"\"\n",
        "    Convierte un tiempo SRT (HH:MM:SS,ms) a segundos (float).\n",
        "    \"\"\"\n",
        "    hours, minutes, rest = timestr.split(':')\n",
        "    seconds, ms = rest.split(',')\n",
        "    return int(hours) * 3600 + int(minutes) * 60 + int(seconds) + int(ms) / 1000\n",
        "\n",
        "\n",
        "def load_srt(srt_path):\n",
        "    \"\"\"\n",
        "    Parsea un archivo .srt y devuelve una lista de frases con start, end y texto.\n",
        "    \"\"\"\n",
        "    phrases = []\n",
        "    with open(srt_path, 'r', encoding='utf-8') as f:\n",
        "        content = f.read().strip()\n",
        "\n",
        "    blocks = re.split(r'\\n\\n+', content)\n",
        "    for block in blocks:\n",
        "        lines = block.splitlines()\n",
        "        if len(lines) >= 3:\n",
        "            start_str, end_str = lines[1].split(' --> ')\n",
        "            start = parse_srt_time(start_str.strip())\n",
        "            end = parse_srt_time(end_str.strip())\n",
        "            text = ' '.join(lines[2:]).strip()\n",
        "            phrases.append({'start': start, 'end': end, 'text': text})\n",
        "    return phrases\n",
        "\n",
        "\n",
        "def load_alignment_json(aligned_json_path):\n",
        "    \"\"\"\n",
        "    Carga el JSON alineado y devuelve la lista de palabras con tiempos.\n",
        "    Soporta:\n",
        "      - Formato WhisperX completo: {'segments': [...], ...}\n",
        "      - Formato simplificado: [{ 'word'|'text', 'start', 'end' }, ...]\n",
        "    \"\"\"\n",
        "    with open(aligned_json_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # WhisperX completo\n",
        "    if isinstance(data, dict) and 'segments' in data:\n",
        "        words = []\n",
        "        for seg in data['segments']:\n",
        "            words.extend(seg.get('words', []))\n",
        "    # Formato lista de palabras\n",
        "    elif isinstance(data, list) and isinstance(data[0], dict):\n",
        "        words = data\n",
        "    else:\n",
        "        raise ValueError(\"Formato de JSON alineado no v√°lido\")\n",
        "    return words\n",
        "\n",
        "\n",
        "def assign_filter(text, index):\n",
        "    \"\"\"Asigna filtro favoreciendo el tipo 1 y ocasionalmente del 2 al 5\"\"\"\n",
        "    if random.random() < 0.8:\n",
        "        return 1\n",
        "    else:\n",
        "        return random.randint(2, 3)\n",
        "\n",
        "def assign_font(text):\n",
        "    \"\"\"Fuente Impact si est√° en MAY√öSCULAS, BebasNeue en otro caso.\"\"\"\n",
        "    if text.isupper():\n",
        "        return \"PoetsenOne-Regular.ttf\"\n",
        "    return \"PoetsenOne-Regular.ttf\"\n",
        "\n",
        "\n",
        "def is_closing_word(word, phrases, phrase_id):\n",
        "    \"\"\"Marca si la palabra es la √∫ltima de su frase (umbral 0.1s)\"\"\"\n",
        "    phrase = phrases[phrase_id] if phrase_id is not None else None\n",
        "    if not phrase:\n",
        "        return False\n",
        "    return abs(word['end'] - phrase['end']) < 0.1\n",
        "\n",
        "\n",
        "def get_phrase_id(word, phrases):\n",
        "    \"\"\"Retorna el √≠ndice de la frase donde encaja la palabra seg√∫n tiempos.\"\"\"\n",
        "    for i, p in enumerate(phrases):\n",
        "        if word['start'] >= p['start'] and word['end'] <= p['end']:\n",
        "            return i\n",
        "    return None\n",
        "\n",
        "\n",
        "def build_visual_metadata(srt_file, aligned_json_file, output_json):\n",
        "    phrases = load_srt(srt_file)\n",
        "    words = load_alignment_json(aligned_json_file)\n",
        "    result = []\n",
        "\n",
        "    for i, w in enumerate(words):\n",
        "        text = w.get('word', w.get('text', '')).strip()\n",
        "        start = w['start']\n",
        "        end = w['end']\n",
        "        duration = end - start\n",
        "        phrase_id = get_phrase_id(w, phrases)\n",
        "        filter_type = assign_filter(text, i)\n",
        "        font = assign_font(text)\n",
        "        closing = is_closing_word(w, phrases, phrase_id)\n",
        "\n",
        "        result.append({\n",
        "            \"text\": text,\n",
        "            \"start\": start,\n",
        "            \"end\": end,\n",
        "            \"duration\": duration,\n",
        "            \"font\": font,\n",
        "            \"filter_type\": filter_type,\n",
        "            \"is_closing_word\": closing,\n",
        "            \"phrase_id\": phrase_id\n",
        "        })\n",
        "\n",
        "    with open(output_json, 'w', encoding='utf-8') as f:\n",
        "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"Visual metadata guardada en '{output_json}'\")\n",
        "\n",
        "# Notebook/Colab usage:\n",
        "aligned_json_file = \"audio.aligned.json\"\n",
        "output_json = \"visual_metadata.json\"\n",
        "if os.path.exists(output_json):\n",
        "  os.remove(output_json)\n",
        "\n",
        "srt_file = \"audio.srt\"\n",
        "build_visual_metadata(srt_file, aligned_json_file, output_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ7Liop1_zWP",
        "outputId": "749dd8c1-fa0c-448d-9327-0685b7a448fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visual metadata guardada en 'visual_metadata.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import string\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# ---------------- CONFIGURACI√ìN ----------------\n",
        "DATA_FILE        = \"visual_metadata.json\"  # JSON generado con metadata visual\n",
        "OUTPUT_ROOT      = \"imagenes_por_frase\"    # Carpeta ra√≠z de salida\n",
        "ANCHO, ALTO      = 1080, 1920               # Dimensiones de cada imagen\n",
        "FUENTE_DIR       = \"\"               # Carpeta donde guardas tus .ttf\n",
        "BASE_FONT_SIZE   = 120                      # Tama√±o base de fuente\n",
        "COLOR_FONDO       = (0, 0, 0)\n",
        "COLOR_TEXTO       = (255, 255, 255)\n",
        "MAX_WORDS_PER_LINE = 2\n",
        "# -----------------------------------------------\n",
        "\"\"\"\n",
        "def draw_text_multiline(draw, text, font, max_width, start_y):\n",
        "    words = text.strip().split()\n",
        "    lines, current = [], \"\"\n",
        "    for w in words:\n",
        "        test = (current + \" \" + w).strip()\n",
        "        if draw.textlength(test, font=font) <= max_width:\n",
        "            current = test\n",
        "        else:\n",
        "            lines.append(current)\n",
        "            current = w\n",
        "    if current:\n",
        "        lines.append(current)\n",
        "\n",
        "    bbox = font.getbbox(\"A\")\n",
        "    line_h = (bbox[3] - bbox[1]) + 15\n",
        "    total_h = line_h * len(lines)\n",
        "    y = start_y - total_h // 2\n",
        "    for line in lines:\n",
        "        w = draw.textlength(line, font=font)\n",
        "        x = (ANCHO - w) // 2\n",
        "        draw.text((x, y), line, font=font, fill=COLOR_TEXTO)\n",
        "        y += line_h\n",
        "\n",
        "\"\"\"\n",
        "def draw_text_multiline(draw, text, font, max_width, start_y):\n",
        "    \"\"\"\n",
        "    Dibuja texto centrado, respetando max_width y MAX_WORDS_PER_LINE. Palabras con may√∫sculas indican estilo destacado.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = []\n",
        "\n",
        "    for word in words:\n",
        "        current_line.append(word)\n",
        "        if len(current_line) >= MAX_WORDS_PER_LINE:\n",
        "            lines.append(current_line)\n",
        "            current_line = []\n",
        "    if current_line:\n",
        "        lines.append(current_line)\n",
        "\n",
        "    # Dibujar l√≠neas\n",
        "    line_height = font.getbbox(\"Ay\")[3] - font.getbbox(\"Ay\")[1] + 20\n",
        "    total_height = len(lines) * line_height\n",
        "    y = start_y - total_height // 2\n",
        "\n",
        "    for line in lines:\n",
        "        line_text = \" \".join(line)\n",
        "        line_width = draw.textlength(line_text, font=font)\n",
        "        x = (ANCHO - line_width) // 2\n",
        "        draw.text((x, y), line_text, font=font, fill=COLOR_TEXTO)\n",
        "        y += line_height\n",
        "\n",
        "def ensure_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Cargar metadata completa\n",
        "    with open(DATA_FILE, 'r', encoding='utf-8') as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "    # Ordenar por tiempo de inicio y rellenar phrase_id faltantes\n",
        "    metadata = sorted(metadata, key=lambda x: x.get('start', 0))\n",
        "    last_pid = None\n",
        "    for item in metadata:\n",
        "        if item.get('phrase_id') is not None:\n",
        "            last_pid = item['phrase_id']\n",
        "        else:\n",
        "            item['phrase_id'] = last_pid\n",
        "\n",
        "    # Agrupar por parte entera de phrase_id\n",
        "    groups = {}\n",
        "    for item in metadata:\n",
        "        pid = float(item['phrase_id']) if item.get('phrase_id') is not None else 0.0\n",
        "        key = int(pid)\n",
        "        groups.setdefault(key, []).append(item)\n",
        "\n",
        "    # Procesar cada frase-grupo\n",
        "    for group_id, items in sorted(groups.items()):\n",
        "        folder = os.path.join(OUTPUT_ROOT, f\"frase_{group_id:04d}\")\n",
        "        ensure_dir(folder)\n",
        "\n",
        "        # Ordenar por phrase_id decimal y luego por tiempo\n",
        "        items_sorted = sorted(\n",
        "            items,\n",
        "            key=lambda x: (float(x['phrase_id']), x.get('start', 0))\n",
        "        )\n",
        "\n",
        "        # Intentar cargar fuente base\n",
        "        font_name = items_sorted[0].get('font', '')\n",
        "        base_path = os.path.join(FUENTE_DIR, font_name)\n",
        "        try:\n",
        "            ImageFont.truetype(base_path, BASE_FONT_SIZE)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è No se pudo cargar fuente '{base_path}': {e}. Usando defecto.\")\n",
        "            base_path = None\n",
        "\n",
        "        text_accum = \"\"\n",
        "        prev_end = None\n",
        "        metadata_list = []\n",
        "        counter = 0\n",
        "\n",
        "        for w in items_sorted:\n",
        "            palabra = w['text']\n",
        "            style = int(w.get('filter_type', 1))\n",
        "            start, end = w.get('start'), w.get('end')\n",
        "            prev_accum = text_accum\n",
        "\n",
        "            # Construir textos y tama√±os seg√∫n estilo\n",
        "            texts, sizes = [], []\n",
        "            if style == 1:\n",
        "                text_accum += palabra + \" \"\n",
        "                texts = [text_accum.strip()]\n",
        "                sizes = [BASE_FONT_SIZE*1.1]\n",
        "            elif style == 2:\n",
        "                # Mostrar acumulado anterior + palabra destacada abajo\n",
        "                #Yo no quiero que se genere sola y grande, yo quoero que cuando se gnere al imagen se genere mas grande y que esa palabra avlga por dos\n",
        "                # Mostrar la palabra sola, en grande, en su propia l√≠nea sin acumular a√∫n\n",
        "                texts = [text_accum.strip() ]\n",
        "                sizes = [BASE_FONT_SIZE * 1.4]\n",
        "\n",
        "            elif style == 3:\n",
        "                text_accum += palabra + \" \"\n",
        "                letters = len(palabra)\n",
        "                for i in range(1, letters + 1):\n",
        "                    texts.append(prev_accum + palabra[:i])\n",
        "                    sizes.append(BASE_FONT_SIZE)\n",
        "            else:\n",
        "                text_accum += palabra + \" \"\n",
        "                texts = [text_accum.strip()]\n",
        "                sizes = [BASE_FONT_SIZE]\n",
        "\n",
        "            # Renderizar frames\n",
        "            for idx, (txt, size) in enumerate(zip(texts, sizes)):\n",
        "                try:\n",
        "                    img = Image.new('RGB', (ANCHO, ALTO), COLOR_FONDO)\n",
        "                    draw = ImageDraw.Draw(img)\n",
        "                    font = ImageFont.truetype(base_path, size) if base_path else ImageFont.load_default()\n",
        "                    draw_text_multiline(draw, txt, font, ANCHO - 100, ALTO // 2)\n",
        "\n",
        "                    # Nombre de archivo\n",
        "                    name = f\"palabra_{counter:03d}\"\n",
        "                    if len(texts) > 1:\n",
        "                        name += f\"_{idx:02d}\"\n",
        "                    name += \".png\"\n",
        "                    img.save(os.path.join(folder, name))\n",
        "\n",
        "                    # Metadata para √∫ltimo frame de la palabra\n",
        "                    if idx == len(texts) - 1:\n",
        "                        if start is not None and end is not None:\n",
        "                            dur = (end - prev_end) if prev_end is not None else (end - start)\n",
        "                            prev_end = end\n",
        "                        else:\n",
        "                            dur = 0.0\n",
        "                        metadata_list.append({\n",
        "                            \"archivo\": name,\n",
        "                            \"start\": round(start or 0.0, 3),\n",
        "                            \"end\": round(end or 0.0, 3),\n",
        "                            \"duration\": round(dur, 3)\n",
        "                        })\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå ERROR al renderizar '{palabra}', estilo {style}, frame {idx}: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # Para style 2, concatenar despu√©s de renderizado\n",
        "            # Dentro del bloque render:\n",
        "            \"\"\"if style == 2:\n",
        "              text_accum += palabra + \"\" \"\"\"\n",
        "\n",
        "\n",
        "            counter += 1\n",
        "\n",
        "        # Guardar metadata.json\n",
        "        with open(os.path.join(folder, 'metadata.json'), 'w', encoding='utf-8') as mf:\n",
        "            json.dump(metadata_list, mf, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"‚úÖ Finalizado: {len(groups)} frases generadas en '{OUTPUT_ROOT}'\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvHqexJpnn2E",
        "outputId": "cd8644cf-5e83-4c1a-9715-55a583fb6c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Finalizado: 9 frases generadas en 'imagenes_por_frase'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# ‚Äî‚Äî‚Äî‚Äî‚Äî CONFIGURACI√ìN ‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "CARPETA_SALIDA = \"imagenes_por_frase\"\n",
        "OUTPUT_FILE   = \"inputs.txt\"\n",
        "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "\n",
        "# 1) Leemos todas las carpetas de frase\n",
        "entries = []\n",
        "for frase in sorted(os.listdir(CARPETA_SALIDA)):\n",
        "    path_frase = os.path.join(CARPETA_SALIDA, frase)\n",
        "    metadata_path = os.path.join(path_frase, \"metadata.json\")\n",
        "    if not os.path.isdir(path_frase) or not os.path.isfile(metadata_path):\n",
        "        continue\n",
        "\n",
        "    # 2) Cargamos el metadata.json de esa frase\n",
        "    with open(metadata_path, \"r\", encoding=\"utf-8\") as mf:\n",
        "        metadata = json.load(mf)\n",
        "\n",
        "    # 3) A√±adimos ruta absoluta de cada imagen\n",
        "    for item in metadata:\n",
        "        # Ruta completa al PNG\n",
        "        item[\"path\"] = os.path.join(path_frase, item[\"archivo\"])\n",
        "        entries.append(item)\n",
        "\n",
        "# 4) Ordenamos globalmente por el start time\n",
        "entries = [e for e in entries if e.get(\"start\") is not None]\n",
        "entries.sort(key=lambda e: e[\"start\"])\n",
        "\n",
        "# 5) Escribimos inputs.txt usando el duration de CADA imagen\n",
        "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as fout:\n",
        "    for e in entries:\n",
        "        ruta = e[\"path\"]\n",
        "        dur  = e.get(\"duration\", 0.1)  # fallback 0.1s si falta duration\n",
        "        fout.write(f\"file '{ruta}'\\n\")\n",
        "        fout.write(f\"duration {dur}\\n\")\n",
        "\n",
        "    # FFmpeg necesita repetir la √∫ltima imagen sin duration\n",
        "    if entries:\n",
        "        fout.write(f\"file '{entries[-1]['path']}'\\n\")\n",
        "\n",
        "print(f\"‚úÖ '{OUTPUT_FILE}' regenerado con duraciones individuales por imagen.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy4EwZKmrexR",
        "outputId": "b5c4734b-d497-466a-bcb4-64c15b87acf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 'inputs.txt' regenerado con duraciones individuales por imagen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shutil\n",
        "#esto ya lo genera bien bien\n",
        "def build_video_constant_fps(\n",
        "    inputs_txt=\"inputs.txt\",\n",
        "    audio_file=\"audio.mp3\",\n",
        "    output_file=\"salida.mp4\",\n",
        "    fps=30,\n",
        "    temp_dir=\"__frames_temp__\"\n",
        "):\n",
        "    # 1. Validar existencia\n",
        "    if not os.path.isfile(inputs_txt):\n",
        "        print(f\"‚ùå No existe {inputs_txt}\"); sys.exit(1)\n",
        "    if not os.path.isfile(audio_file):\n",
        "        print(f\"‚ùå No existe {audio_file}\"); sys.exit(1)\n",
        "\n",
        "    # 2. Leer inputs.txt ‚Üí lista (ruta, duraci√≥n)\n",
        "    seq = []\n",
        "    with open(inputs_txt, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = [l.strip() for l in f if l.strip()]\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        if lines[i].startswith(\"file\"):\n",
        "            path = lines[i].split(\"'\",2)[1]\n",
        "            dur = None\n",
        "            if i+1<len(lines) and lines[i+1].startswith(\"duration\"):\n",
        "                dur = float(lines[i+1].split()[1])\n",
        "                i += 2\n",
        "            else:\n",
        "                i += 1\n",
        "            seq.append((path, dur))\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    # 3. Preparar carpeta temporal limpia\n",
        "    if os.path.isdir(temp_dir): shutil.rmtree(temp_dir)\n",
        "    os.makedirs(temp_dir)\n",
        "\n",
        "    # 4. Expandir cada imagen n_frames = round(dur * fps)\n",
        "    frame_idx = 0\n",
        "    for img_path, dur in seq:\n",
        "        if dur is None or dur <= 0:\n",
        "            continue\n",
        "        n_frames = max(1, int(round(dur * fps)))\n",
        "        for _ in range(n_frames):\n",
        "            dst = os.path.join(temp_dir, f\"frame_{frame_idx:06d}.png\")\n",
        "            # copiar para evitar posibles issues con hard links\n",
        "            shutil.copy(img_path, dst)\n",
        "            frame_idx += 1\n",
        "\n",
        "    if frame_idx == 0:\n",
        "        print(\"‚ùå Ning√∫n frame generado.\"); sys.exit(1)\n",
        "    print(f\"‚ÑπÔ∏è  Generados {frame_idx} frames en {temp_dir}/\")\n",
        "\n",
        "    # 5. Comando FFmpeg con mapeo expl√≠cito y start_number\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-y\",\n",
        "        \"-framerate\", str(fps),\n",
        "        \"-start_number\", \"0\",\n",
        "        \"-i\", os.path.join(temp_dir, \"frame_%06d.png\"),\n",
        "        \"-i\", audio_file,\n",
        "        \"-map\", \"0:v:0\",        # video del primer input\n",
        "        \"-map\", \"1:a:0\",        # audio del segundo input\n",
        "        \"-c:v\", \"libx264\",\n",
        "        \"-pix_fmt\", \"yuv420p\",\n",
        "        \"-c:a\", \"aac\",\n",
        "        \"-shortest\",\n",
        "        \"-movflags\", \"+faststart\",\n",
        "        output_file\n",
        "    ]\n",
        "\n",
        "    print(\"üîß Ejecutando FFmpeg:\")\n",
        "    print(\" \".join(cmd))\n",
        "    try:\n",
        "        proc = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "        print(f\"‚úÖ Video generado: {output_file}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"‚ùå FFmpeg fall√≥ (retcode={}):\".format(e.returncode))\n",
        "        print(e.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # 6. Limpiar carpeta\n",
        "    shutil.rmtree(temp_dir)\n",
        "    print(f\"üßπ Carpeta temporal {temp_dir} eliminada.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    build_video_constant_fps()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jndQve2xbXI",
        "outputId": "80a3957d-d9d2-4756-9f36-65dcea397a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ÑπÔ∏è  Generados 940 frames en __frames_temp__/\n",
            "üîß Ejecutando FFmpeg:\n",
            "ffmpeg -y -framerate 30 -start_number 0 -i __frames_temp__/frame_%06d.png -i audio.mp3 -map 0:v:0 -map 1:a:0 -c:v libx264 -pix_fmt yuv420p -c:a aac -shortest -movflags +faststart salida.mp4\n",
            "‚úÖ Video generado: salida.mp4\n",
            "üßπ Carpeta temporal __frames_temp__ eliminada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Secci√≥n nueva"
      ],
      "metadata": {
        "id": "WT1__1Jx_mkO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2I7k0VH6sIW"
      },
      "source": [
        "# GENERACION DE IMAGENES PARA VIDEOS AUTOMATICOS Y RENDERIZADO üé¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "2wPwwProjeFJ",
        "outputId": "5af5c818-2f7d-4beb-eb7d-f408e645f31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ÑπÔ∏è No se gener√≥ offset: empieza muy cerca de 0s.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "cannot open resource",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3bc436cc0450>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;31m# 3) Preparar carpeta de salida y fuente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCARPETA_SALIDA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mfuente\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFUENTE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTAMANO_FUENTE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# 4) Recorrer aligned_words y construir im√°genes frase a frase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36mtruetype\u001b[0;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfreetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36mfreetype\u001b[0;34m(font)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfreetype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStrOrBytesPath\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mBinaryIO\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mFreeTypeFont\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mFreeTypeFont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    282\u001b[0m                         \u001b[0mload_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             self.font = core.getfont(\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayout_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             )\n",
            "\u001b[0;31mOSError\u001b[0m: cannot open resource"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import string\n",
        "from datetime import timedelta\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "# ESTA ES LA PRIMERA VERCION DE LA GENERACION DE IMAGNES SIRVE DE EJEMPLO PARA LOS OTROS\n",
        "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî CONFIGURACI√ìN ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "ANCHO, ALTO       = 1080, 1920\n",
        "CARPETA_SALIDA    = \"imagenes_por_frase\"\n",
        "SRT_FILE          = \"audio.srt\"             # tu archivo SRT de Whisper\n",
        "JSON_ALIGNED      = \"audio.aligned.json\"    # JSON alineado de WhisperX\n",
        "FUENTE_PATH       = \"/content/PoetsenOne-Regular.ttf\"\n",
        "TAMANO_FUENTE     = 120\n",
        "COLOR_FONDO       =  (0, 0, 0)\n",
        "COLOR_TEXTO       =  (255,   255,   255)\n",
        "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "def generar_offset_inicial(aligned_words, carpeta_salida, ancho, alto, color_fondo):\n",
        "    \"\"\"\n",
        "    Genera imagen negra inicial si el audio no empieza desde 0s.\n",
        "    Si la primera palabra tiene start == None, se usa 0.0 como valor.\n",
        "    \"\"\"\n",
        "    primer_start = None\n",
        "\n",
        "    for palabra in aligned_words:\n",
        "        start = palabra.get(\"start\")\n",
        "        if start is not None:\n",
        "            primer_start = start\n",
        "            break\n",
        "        else:\n",
        "            primer_start = 0.0\n",
        "            break  # asumimos que la primera palabra sin timestamp empieza desde cero\n",
        "\n",
        "    if primer_start is not None and primer_start > 0.1:  # ignorar silencios muuuy cortos\n",
        "        carpeta_offset = os.path.join(carpeta_salida, \"frase_0000\")\n",
        "        os.makedirs(carpeta_offset, exist_ok=True)\n",
        "\n",
        "        # Crear imagen negra\n",
        "        img = Image.new(\"RGB\", (ancho, alto), color_fondo)\n",
        "        nombre_img = \"offset_000.png\"\n",
        "        ruta_img   = os.path.join(carpeta_offset, nombre_img)\n",
        "        img.save(ruta_img)\n",
        "\n",
        "        # Guardar metadata\n",
        "        metadata = [{\n",
        "            \"archivo\":  nombre_img,\n",
        "            \"start\":    0.0,\n",
        "            \"end\":      primer_start,\n",
        "            \"duration\": primer_start\n",
        "        }]\n",
        "        with open(os.path.join(carpeta_offset, \"metadata.json\"), \"w\", encoding=\"utf-8\") as mf:\n",
        "            json.dump(metadata, mf, ensure_ascii=False, indent=2)\n",
        "\n",
        "        print(f\"üïí Offset generado correctamente hasta {primer_start:.2f}s\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è No se gener√≥ offset: empieza muy cerca de 0s.\")\n",
        "\n",
        "\n",
        "# helper: convierte \"HH:MM:SS,mmm\" ‚Üí segundos (float)\n",
        "def parse_timestamp(ts: str) -> float:\n",
        "    h, m, rest = ts.split(\":\", 2)\n",
        "    s, ms      = rest.split(\",\", 1)\n",
        "    return int(h)*3600 + int(m)*60 + int(s) + int(ms)/1000.0\n",
        "\n",
        "\n",
        "# funci√≥n para dibujar texto envuelto y centrado\n",
        "def draw_text_multiline(draw, text, font, max_width_px, start_y):\n",
        "    words = text.strip().split()\n",
        "    lines = []\n",
        "    current_line = \"\"\n",
        "    for word in words:\n",
        "        test_line = f\"{current_line} {word}\".strip()\n",
        "        if draw.textlength(test_line, font=font) <= max_width_px:\n",
        "            current_line = test_line\n",
        "        else:\n",
        "            lines.append(current_line)\n",
        "            current_line = word\n",
        "    if current_line:\n",
        "        lines.append(current_line)\n",
        "\n",
        "    # centrar verticalmente\n",
        "    line_height = font.getbbox(\"A\")[3] - font.getbbox(\"A\")[1] + 15\n",
        "    total_height = line_height * len(lines)\n",
        "    y = start_y - total_height // 2\n",
        "\n",
        "    for line in lines:\n",
        "        line_width = draw.textlength(line, font=font)\n",
        "        x = (ANCHO - line_width) // 2\n",
        "        draw.text((x, y), line, font=font, fill=COLOR_TEXTO)\n",
        "        y += line_height\n",
        "\n",
        "# 1) Parsear SRT para obtener la lista de palabras finales de cada frase\n",
        "final_words = []\n",
        "with open(SRT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_blocks = f.read().strip().split(\"\\n\\n\")\n",
        "\n",
        "for block in raw_blocks:\n",
        "    lines = block.splitlines()\n",
        "    if len(lines) < 3:\n",
        "        continue\n",
        "    text = \" \".join(lines[2:]).strip()\n",
        "    if not text:\n",
        "        continue\n",
        "    last = text.split()[-1]\n",
        "    # limpiar puntuaci√≥n y normalizar\n",
        "    last_clean = last.strip(string.punctuation).lower()\n",
        "    final_words.append(last_clean)\n",
        "\n",
        "# 2) Cargar palabras alineadas desde JSON, sea lista o segmentos\n",
        "with open(JSON_ALIGNED, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "aligned_words = []\n",
        "generar_offset_inicial(aligned_words, CARPETA_SALIDA, ANCHO, ALTO, COLOR_FONDO)\n",
        "\n",
        "if isinstance(data, dict) and \"segments\" in data:\n",
        "    # Caso t√≠pico de WhisperX con segments y palabras dentro\n",
        "    for seg in data[\"segments\"]:\n",
        "        if isinstance(seg, dict) and \"words\" in seg:\n",
        "            aligned_words.extend(seg[\"words\"])\n",
        "\n",
        "elif isinstance(data, list) and all(isinstance(item, dict) and \"word\" in item for item in data):\n",
        "    # Lista directa de palabras\n",
        "    aligned_words = data\n",
        "\n",
        "else:\n",
        "    raise ValueError(\"Formato de audio.aligned.json no reconocido.\")\n",
        "\n",
        "\n",
        "# 3) Preparar carpeta de salida y fuente\n",
        "os.makedirs(CARPETA_SALIDA, exist_ok=True)\n",
        "fuente = ImageFont.truetype(FUENTE_PATH, TAMANO_FUENTE)\n",
        "\n",
        "# 4) Recorrer aligned_words y construir im√°genes frase a frase\n",
        "phrase_idx      = 0\n",
        "phrase_folder   = None\n",
        "metadata        = []\n",
        "text_accum      = \"\"\n",
        "previous_end    = None\n",
        "word_counter    = 0\n",
        "outputs_created = 0\n",
        "\n",
        "for w in aligned_words:\n",
        "    if phrase_idx >= len(final_words):\n",
        "        break  # ya no hay m√°s frases definidas en el SRT\n",
        "\n",
        "    word_text       = w[\"word\"]\n",
        "    start, end      = w.get(\"start\"), w.get(\"end\")\n",
        "    key_last        = final_words[phrase_idx]\n",
        "    # normalizar palabra actual\n",
        "    cleaned = word_text.strip(string.punctuation).lower()\n",
        "\n",
        "    # Inicializar carpeta de frase si es la primera palabra\n",
        "    if phrase_folder is None:\n",
        "        phrase_folder = os.path.join(CARPETA_SALIDA, f\"frase_{phrase_idx:04d}\")\n",
        "        os.makedirs(phrase_folder, exist_ok=True)\n",
        "\n",
        "    # Acumular texto y crear imagen\n",
        "    text_accum += word_text + \" \"\n",
        "    img = Image.new(\"RGB\", (ANCHO, ALTO), COLOR_FONDO)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    draw_text_multiline(draw, text_accum.strip(), fuente, ANCHO - 100, ALTO // 2)\n",
        "\n",
        "    nombre_img = f\"palabra_{word_counter:03d}.png\"\n",
        "    ruta_img   = os.path.join(phrase_folder, nombre_img)\n",
        "    img.save(ruta_img)\n",
        "\n",
        "    # Calcular duraci√≥n\n",
        "    if start is not None and end is not None:\n",
        "        if previous_end is None:\n",
        "            dur = end - start\n",
        "        else:\n",
        "            dur = end - previous_end\n",
        "        previous_end = end\n",
        "    else:\n",
        "        dur = None\n",
        "\n",
        "    metadata.append({\n",
        "        \"archivo\":  nombre_img,\n",
        "        \"start\":    round(start, 3) if start else None,\n",
        "        \"end\":      round(end, 3)   if end   else None,\n",
        "        \"duration\": round(dur, 3)   if dur   else None\n",
        "    })\n",
        "\n",
        "    word_counter += 1\n",
        "\n",
        "    # Si esta palabra es la √∫ltima de la frase, cerrar y resetear\n",
        "    if cleaned == key_last:\n",
        "        for item in metadata:\n",
        "          if item['start'] is None:\n",
        "              item['start'] = 0.0  # reemplazamos None por 0.0\n",
        "          if item['end'] is None:\n",
        "              item['end'] = 0.0    # reemplazamos None por 0.0\n",
        "\n",
        "        # guardar metadata.json\n",
        "        with open(os.path.join(phrase_folder, \"metadata.json\"), \"w\", encoding=\"utf-8\") as mf:\n",
        "            json.dump(metadata, mf, ensure_ascii=False, indent=2)\n",
        "        # reset para la siguiente frase\n",
        "        phrase_idx   += 1\n",
        "        phrase_folder = None\n",
        "        metadata      = []\n",
        "        text_accum    = \"\"\n",
        "        previous_end  = None\n",
        "        word_counter  = 0\n",
        "        outputs_created += 1\n",
        "\n",
        "print(f\"‚úÖ Generadas {outputs_created} frases con im√°genes y metadata.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9zbAq3crtjx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rVoQQ6i82UM",
        "outputId": "9d1a1050-943f-4995-8f3f-8704e8a9fe53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Im√°genes y metadata generadas con √©xito.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "# eSTE CODFIGO GENERA UNA IMAGEN POR CADA PALABRA\n",
        "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî CONFIGURACI√ìN ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "ANCHO, ALTO       = 1080, 1920\n",
        "CARPETA_SALIDA    = \"imagenes_por_frase\"\n",
        "ARCHIVO_JSON      = \"audio.aligned.json\"\n",
        "FUENTE_PATH       = \"/content/fuentes/Roboto-Bold.ttf\"  # ‚Üê ya existe y es v√°lida\n",
        "TAMANO_FUENTE     = 120\n",
        "COLOR_FONDO       = (0, 0, 0)\n",
        "COLOR_TEXTO       = (255, 255, 255)\n",
        "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "\n",
        "# 1) Cargo JSON\n",
        "with open(ARCHIVO_JSON, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# 2) Determino la lista de segmentos\n",
        "if isinstance(data, dict) and \"segments\" in data:\n",
        "    segments = data[\"segments\"]\n",
        "elif isinstance(data, list):\n",
        "    segments = data\n",
        "else:\n",
        "    raise ValueError(\"JSON no tiene formato esperado (ni dict['segments'] ni list)\")\n",
        "\n",
        "# 3) Preparo carpeta de salida y fuente\n",
        "os.makedirs(CARPETA_SALIDA, exist_ok=True)\n",
        "fuente = ImageFont.truetype(FUENTE_PATH, TAMANO_FUENTE)\n",
        "\n",
        "# 4) Recorro cada frase/segmento\n",
        "for i, segment in enumerate(segments):\n",
        "    # Extraigo lista de palabras (puede venir como lista de dicts o de strings)\n",
        "    if isinstance(segment, dict) and \"word\" in segment:\n",
        "        palabras = segment[\"word\"]\n",
        "    elif isinstance(segment, dict) and \"text\" in segment:\n",
        "        # fallback: solo texto sin timestamps\n",
        "        palabras = [{\"word\": w} for w in segment[\"text\"].split()]\n",
        "    else:\n",
        "        # si no viene en ninguno de esos formatos, lo salto\n",
        "        continue\n",
        "\n",
        "    # Carpeta para esta frase\n",
        "    carpeta_frase = os.path.join(CARPETA_SALIDA, f\"frase_{i:04d}\")\n",
        "    os.makedirs(carpeta_frase, exist_ok=True)\n",
        "\n",
        "    texto_acumulado = \"\"\n",
        "    previous_end   = None\n",
        "    metadata       = []\n",
        "\n",
        "    # 5) Por cada palabra, genero imagen + metadato\n",
        "    for j, palabra in enumerate(palabras):\n",
        "        # Normalizo el texto y tiempos\n",
        "        if isinstance(palabra, dict):\n",
        "            w      = palabra.get(\"word\", \"\")\n",
        "            start  = palabra.get(\"start\", None)\n",
        "            end    = palabra.get(\"end\", None)\n",
        "        else:\n",
        "            w      = str(palabra)\n",
        "            start  = end = None\n",
        "\n",
        "        texto_acumulado += w + \" \"\n",
        "\n",
        "        # ‚Äî Crear imagen\n",
        "        img  = Image.new(\"RGB\", (ANCHO, ALTO), COLOR_FONDO)\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        bbox = draw.textbbox((0,0), texto_acumulado.strip(), font=fuente)\n",
        "        tw   = bbox[2] - bbox[0]\n",
        "        th   = bbox[3] - bbox[1]\n",
        "        x    = (ANCHO - tw) // 2\n",
        "        y    = (ALTO  - th) // 2\n",
        "        draw.text((x, y), texto_acumulado.strip(), font=fuente, fill=COLOR_TEXTO)\n",
        "\n",
        "        # ‚Äî Guardar imagen\n",
        "        nombre_img = f\"palabra_{j:03d}.png\"\n",
        "        ruta_img   = os.path.join(carpeta_frase, nombre_img)\n",
        "        img.save(ruta_img)\n",
        "\n",
        "        # ‚Äî Calcular duraci√≥n real (si hay timestamps)\n",
        "        if end is not None:\n",
        "            if previous_end is None:\n",
        "                dur = (end - start) if start is not None else None\n",
        "                ini = start\n",
        "            else:\n",
        "                dur = end - previous_end\n",
        "                ini = previous_end\n",
        "            previous_end = end\n",
        "        else:\n",
        "            ini = dur = None\n",
        "\n",
        "        metadata.append({\n",
        "            \"archivo\": nombre_img,\n",
        "            \"start\":   ini,\n",
        "            \"end\":     end,\n",
        "            \"duration\": dur\n",
        "        })\n",
        "\n",
        "    # 6) Escribo metadata.json\n",
        "    with open(os.path.join(carpeta_frase, \"metadata.json\"), \"w\", encoding=\"utf-8\") as mf:\n",
        "        json.dump(metadata, mf, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"‚úÖ Im√°genes y metadata generadas con √©xito.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XazlFYzOALTM",
        "outputId": "62668fc4-84ac-4a7d-e2fe-f6ca421f438c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 'inputs.txt' regenerado con duraciones individuales por imagen.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# ‚Äî‚Äî‚Äî‚Äî‚Äî CONFIGURACI√ìN ‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "CARPETA_SALIDA = \"imagenes_por_frase\"\n",
        "OUTPUT_FILE   = \"inputs.txt\"\n",
        "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
        "\n",
        "# 1) Leemos todas las carpetas de frase\n",
        "entries = []\n",
        "for frase in sorted(os.listdir(CARPETA_SALIDA)):\n",
        "    path_frase = os.path.join(CARPETA_SALIDA, frase)\n",
        "    metadata_path = os.path.join(path_frase, \"metadata.json\")\n",
        "    if not os.path.isdir(path_frase) or not os.path.isfile(metadata_path):\n",
        "        continue\n",
        "\n",
        "    # 2) Cargamos el metadata.json de esa frase\n",
        "    with open(metadata_path, \"r\", encoding=\"utf-8\") as mf:\n",
        "        metadata = json.load(mf)\n",
        "\n",
        "    # 3) A√±adimos ruta absoluta de cada imagen\n",
        "    for item in metadata:\n",
        "        # Ruta completa al PNG\n",
        "        item[\"path\"] = os.path.join(path_frase, item[\"archivo\"])\n",
        "        entries.append(item)\n",
        "\n",
        "# 4) Ordenamos globalmente por el start time\n",
        "entries = [e for e in entries if e.get(\"start\") is not None]\n",
        "entries.sort(key=lambda e: e[\"start\"])\n",
        "\n",
        "# 5) Escribimos inputs.txt usando el duration de CADA imagen\n",
        "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as fout:\n",
        "    for e in entries:\n",
        "        ruta = e[\"path\"]\n",
        "        dur  = e.get(\"duration\", 0.1)  # fallback 0.1s si falta duration\n",
        "        fout.write(f\"file '{ruta}'\\n\")\n",
        "        fout.write(f\"duration {dur}\\n\")\n",
        "\n",
        "    # FFmpeg necesita repetir la √∫ltima imagen sin duration\n",
        "    if entries:\n",
        "        fout.write(f\"file '{entries[-1]['path']}'\\n\")\n",
        "\n",
        "print(f\"‚úÖ '{OUTPUT_FILE}' regenerado con duraciones individuales por imagen.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhGdSAyYzYU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d3813fa-be39-498c-9ca7-5dba36f1f4f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ÑπÔ∏è  Generados 1640 frames en __frames_temp__/\n",
            "üîß Ejecutando FFmpeg:\n",
            "ffmpeg -y -framerate 30 -start_number 0 -i __frames_temp__/frame_%06d.png -i audio.mp3 -map 0:v:0 -map 1:a:0 -c:v libx264 -pix_fmt yuv420p -c:a aac -shortest -movflags +faststart salida.mp4\n",
            "‚úÖ Video generado: salida.mp4\n",
            "üßπ Carpeta temporal __frames_temp__ eliminada.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import shutil\n",
        "#esto ya lo genera bien bien\n",
        "def build_video_constant_fps(\n",
        "    inputs_txt=\"inputs.txt\",\n",
        "    audio_file=\"audio.mp3\",\n",
        "    output_file=\"salida.mp4\",\n",
        "    fps=30,\n",
        "    temp_dir=\"__frames_temp__\"\n",
        "):\n",
        "    # 1. Validar existencia\n",
        "    if not os.path.isfile(inputs_txt):\n",
        "        print(f\"‚ùå No existe {inputs_txt}\"); sys.exit(1)\n",
        "    if not os.path.isfile(audio_file):\n",
        "        print(f\"‚ùå No existe {audio_file}\"); sys.exit(1)\n",
        "\n",
        "    # 2. Leer inputs.txt ‚Üí lista (ruta, duraci√≥n)\n",
        "    seq = []\n",
        "    with open(inputs_txt, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = [l.strip() for l in f if l.strip()]\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        if lines[i].startswith(\"file\"):\n",
        "            path = lines[i].split(\"'\",2)[1]\n",
        "            dur = None\n",
        "            if i+1<len(lines) and lines[i+1].startswith(\"duration\"):\n",
        "                dur = float(lines[i+1].split()[1])\n",
        "                i += 2\n",
        "            else:\n",
        "                i += 1\n",
        "            seq.append((path, dur))\n",
        "        else:\n",
        "            i += 1\n",
        "\n",
        "    # 3. Preparar carpeta temporal limpia\n",
        "    if os.path.isdir(temp_dir): shutil.rmtree(temp_dir)\n",
        "    os.makedirs(temp_dir)\n",
        "\n",
        "    # 4. Expandir cada imagen n_frames = round(dur * fps)\n",
        "    frame_idx = 0\n",
        "    for img_path, dur in seq:\n",
        "        if dur is None or dur <= 0:\n",
        "            continue\n",
        "        n_frames = max(1, int(round(dur * fps)))\n",
        "        for _ in range(n_frames):\n",
        "            dst = os.path.join(temp_dir, f\"frame_{frame_idx:06d}.png\")\n",
        "            # copiar para evitar posibles issues con hard links\n",
        "            shutil.copy(img_path, dst)\n",
        "            frame_idx += 1\n",
        "\n",
        "    if frame_idx == 0:\n",
        "        print(\"‚ùå Ning√∫n frame generado.\"); sys.exit(1)\n",
        "    print(f\"‚ÑπÔ∏è  Generados {frame_idx} frames en {temp_dir}/\")\n",
        "\n",
        "    # 5. Comando FFmpeg con mapeo expl√≠cito y start_number\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-y\",\n",
        "        \"-framerate\", str(fps),\n",
        "        \"-start_number\", \"0\",\n",
        "        \"-i\", os.path.join(temp_dir, \"frame_%06d.png\"),\n",
        "        \"-i\", audio_file,\n",
        "        \"-map\", \"0:v:0\",        # video del primer input\n",
        "        \"-map\", \"1:a:0\",        # audio del segundo input\n",
        "        \"-c:v\", \"libx264\",\n",
        "        \"-pix_fmt\", \"yuv420p\",\n",
        "        \"-c:a\", \"aac\",\n",
        "        \"-shortest\",\n",
        "        \"-movflags\", \"+faststart\",\n",
        "        output_file\n",
        "    ]\n",
        "\n",
        "    print(\"üîß Ejecutando FFmpeg:\")\n",
        "    print(\" \".join(cmd))\n",
        "    try:\n",
        "        proc = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
        "        print(f\"‚úÖ Video generado: {output_file}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"‚ùå FFmpeg fall√≥ (retcode={}):\".format(e.returncode))\n",
        "        print(e.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # 6. Limpiar carpeta\n",
        "    shutil.rmtree(temp_dir)\n",
        "    print(f\"üßπ Carpeta temporal {temp_dir} eliminada.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    build_video_constant_fps()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAFRe3wNCAMw"
      },
      "source": [
        "# GENERACION DE VIDEOS AUTOMATICOS 2 üé¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmrKwuk6C5lU"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDbKejfbChX5",
        "outputId": "f9be9ae6-c52f-4443-cca5-6bea6042124b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Instalar ffmpeg y su wrapper en Python\n",
        "!apt update -qq && apt install -y ffmpeg\n",
        "!pip install -q ffmpeg-python\n",
        "\n",
        "# --- CONFIGURACI√ìN INICIAL ---\n",
        "import os\n",
        "\n",
        "# Rutas de archivos\n",
        "video_entrada = \"video_base.mp4\"\n",
        "video_salida = \"video_final.mp4\"\n",
        "\n",
        "# Subt√≠tulo o texto a colocar (esto se puede cambiar por uno generado autom√°ticamente)\n",
        "texto = \"Este es un texto que ir√° encima del video!\"\n",
        "\n",
        "# Par√°metros visuales\n",
        "fuente = \"Arial\"\n",
        "color_texto = \"white\"\n",
        "tama√±o_fuente = 48\n",
        "pos_x = 20\n",
        "pos_y = \"(h - text_h - 20)\"  # Desde abajo hacia arriba\n",
        "\n",
        "# Otras configuraciones\n",
        "modo_vertical = True  # True para videos tipo TikTok/Instagram\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4RQmPokDAbk"
      },
      "source": [
        "# RENDERIZAR VIDEO MANERA 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t65vquoVEsC",
        "outputId": "954fbb74-ea80-4a76-8315-1556d854afa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Archivo eliminado: audio.mp3\n",
            "‚úÖ Archivo eliminado: audioL.mp3\n",
            "‚úÖ Archivo eliminado: audio.txt\n",
            "‚úÖ Archivo eliminado: audio.srt\n",
            "‚ùå No existe: video_final.mp4\n",
            "‚úÖ Archivo eliminado: audio.aligned.json\n",
            "‚úÖ Archivo eliminado: inputs.txt\n"
          ]
        }
      ],
      "source": [
        "#borrar:\n",
        "import os\n",
        "\n",
        "# Lista de archivos a eliminar\n",
        "archivos = [\"audio.mp3\", \"audioL.mp3\", \"audio.txt\", \"audio.srt\", \"video_final.mp4\", \"audio.aligned.json\", \"inputs.txt\"]\n",
        "\n",
        "for archivo in archivos:\n",
        "    if os.path.exists(archivo):\n",
        "        os.remove(archivo)\n",
        "        print(f\"‚úÖ Archivo eliminado: {archivo}\")\n",
        "    else:\n",
        "        print(f\"‚ùå No existe: {archivo}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl6mlvkiWMf-",
        "outputId": "3814a0ba-02ad-4a14-fe7b-a3809e90641b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtro drawtext generado:\n",
            " drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='High':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,0.000)\\,0\\,if(lt(t\\,0.050)\\,(t-0.000)/0.050\\,if(lt(t\\,1.882)\\,1\\,if(lt(t\\,1.932)\\,(1.932-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='quality':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,1.953)\\,0\\,if(lt(t\\,2.003)\\,(t-1.953)/0.050\\,if(lt(t\\,3.271)\\,1\\,if(lt(t\\,3.321)\\,(3.321-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='on':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,3.784)\\,0\\,if(lt(t\\,3.834)\\,(t-3.784)/0.050\\,if(lt(t\\,4.358)\\,1\\,if(lt(t\\,4.408)\\,(4.408-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='the':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,4.428)\\,0\\,if(lt(t\\,4.478)\\,(t-4.428)/0.050\\,if(lt(t\\,5.445)\\,1\\,if(lt(t\\,5.495)\\,(5.495-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='beat.':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,5.515)\\,0\\,if(lt(t\\,5.565)\\,(t-5.515)/0.050\\,if(lt(t\\,6.210)\\,1\\,if(lt(t\\,6.260)\\,(6.260-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Lo':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,6.240)\\,0\\,if(lt(t\\,6.290)\\,(t-6.240)/0.050\\,if(lt(t\\,6.352)\\,1\\,if(lt(t\\,6.402)\\,(6.402-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='fuera':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,6.503)\\,0\\,if(lt(t\\,6.553)\\,(t-6.503)/0.050\\,if(lt(t\\,6.777)\\,1\\,if(lt(t\\,6.827)\\,(6.827-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='del':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,6.888)\\,0\\,if(lt(t\\,6.938)\\,(t-6.888)/0.050\\,if(lt(t\\,6.959)\\,1\\,if(lt(t\\,7.009)\\,(7.009-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='planeta,':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,7.111)\\,0\\,if(lt(t\\,7.161)\\,(t-7.111)/0.050\\,if(lt(t\\,7.567)\\,1\\,if(lt(t\\,7.617)\\,(7.617-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='no,':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,7.678)\\,0\\,if(lt(t\\,7.728)\\,(t-7.678)/0.050\\,if(lt(t\\,7.769)\\,1\\,if(lt(t\\,7.819)\\,(7.819-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='no':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,7.880)\\,0\\,if(lt(t\\,7.930)\\,(t-7.880)/0.050\\,if(lt(t\\,7.891)\\,1\\,if(lt(t\\,7.941)\\,(7.941-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='soy':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,8.082)\\,0\\,if(lt(t\\,8.132)\\,(t-8.082)/0.050\\,if(lt(t\\,8.255)\\,1\\,if(lt(t\\,8.305)\\,(8.305-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='de':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,8.325)\\,0\\,if(lt(t\\,8.375)\\,(t-8.325)/0.050\\,if(lt(t\\,8.377)\\,1\\,if(lt(t\\,8.427)\\,(8.427-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Plut√≥n.':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,8.528)\\,0\\,if(lt(t\\,8.578)\\,(t-8.528)/0.050\\,if(lt(t\\,9.490)\\,1\\,if(lt(t\\,9.540)\\,(9.540-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Soy':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,9.520)\\,0\\,if(lt(t\\,9.570)\\,(t-9.520)/0.050\\,if(lt(t\\,9.733)\\,1\\,if(lt(t\\,9.783)\\,(9.783-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='de':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,9.803)\\,0\\,if(lt(t\\,9.853)\\,(t-9.803)/0.050\\,if(lt(t\\,9.895)\\,1\\,if(lt(t\\,9.945)\\,(9.945-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='la':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,9.965)\\,0\\,if(lt(t\\,10.015)\\,(t-9.965)/0.050\\,if(lt(t\\,10.098)\\,1\\,if(lt(t\\,10.148)\\,(10.148-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='H,':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,10.168)\\,0\\,if(lt(t\\,10.218)\\,(t-10.168)/0.050\\,if(lt(t\\,10.158)\\,1\\,if(lt(t\\,10.208)\\,(10.208-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='no':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,10.472)\\,0\\,if(lt(t\\,10.522)\\,(t-10.472)/0.050\\,if(lt(t\\,10.624)\\,1\\,if(lt(t\\,10.674)\\,(10.674-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='estoy':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,10.694)\\,0\\,if(lt(t\\,10.744)\\,(t-10.694)/0.050\\,if(lt(t\\,10.908)\\,1\\,if(lt(t\\,10.958)\\,(10.958-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='hablando':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,11.039)\\,0\\,if(lt(t\\,11.089)\\,(t-11.039)/0.050\\,if(lt(t\\,11.373)\\,1\\,if(lt(t\\,11.423)\\,(11.423-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='de':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,11.525)\\,0\\,if(lt(t\\,11.575)\\,(t-11.525)/0.050\\,if(lt(t\\,11.596)\\,1\\,if(lt(t\\,11.646)\\,(11.646-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Hilton.':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,12.112)\\,0\\,if(lt(t\\,12.162)\\,(t-12.112)/0.050\\,if(lt(t\\,12.730)\\,1\\,if(lt(t\\,12.780)\\,(12.780-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='De':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,12.760)\\,0\\,if(lt(t\\,12.810)\\,(t-12.760)/0.050\\,if(lt(t\\,12.993)\\,1\\,if(lt(t\\,13.043)\\,(13.043-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='la':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,13.064)\\,0\\,if(lt(t\\,13.114)\\,(t-13.064)/0.050\\,if(lt(t\\,13.074)\\,1\\,if(lt(t\\,13.124)\\,(13.124-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='cabeza,':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,13.145)\\,0\\,if(lt(t\\,13.195)\\,(t-13.145)/0.050\\,if(lt(t\\,13.682)\\,1\\,if(lt(t\\,13.732)\\,(13.732-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Fieffi,':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,13.752)\\,0\\,if(lt(t\\,13.802)\\,(t-13.752)/0.050\\,if(lt(t\\,14.087)\\,1\\,if(lt(t\\,14.137)\\,(14.137-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='los':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,14.157)\\,0\\,if(lt(t\\,14.207)\\,(t-14.157)/0.050\\,if(lt(t\\,14.208)\\,1\\,if(lt(t\\,14.258)\\,(14.258-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='t√≠os':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,14.461)\\,0\\,if(lt(t\\,14.511)\\,(t-14.461)/0.050\\,if(lt(t\\,14.532)\\,1\\,if(lt(t\\,14.582)\\,(14.582-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='de':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,14.603)\\,0\\,if(lt(t\\,14.653)\\,(t-14.603)/0.050\\,if(lt(t\\,14.654)\\,1\\,if(lt(t\\,14.704)\\,(14.704-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Luis':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,14.745)\\,0\\,if(lt(t\\,14.795)\\,(t-14.745)/0.050\\,if(lt(t\\,14.958)\\,1\\,if(lt(t\\,15.008)\\,(15.008-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Bust√≥n.':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,15.028)\\,0\\,if(lt(t\\,15.078)\\,(t-15.028)/0.050\\,if(lt(t\\,15.970)\\,1\\,if(lt(t\\,16.020)\\,(16.020-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Frontean':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,16.000)\\,0\\,if(lt(t\\,16.050)\\,(t-16.000)/0.050\\,if(lt(t\\,16.497)\\,1\\,if(lt(t\\,16.547)\\,(16.547-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='de':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,16.668)\\,0\\,if(lt(t\\,16.718)\\,(t-16.668)/0.050\\,if(lt(t\\,16.922)\\,1\\,if(lt(t\\,16.972)\\,(16.972-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='hoteles':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,16.992)\\,0\\,if(lt(t\\,17.042)\\,(t-16.992)/0.050\\,if(lt(t\\,17.530)\\,1\\,if(lt(t\\,17.580)\\,(17.580-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='y':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,17.600)\\,0\\,if(lt(t\\,17.650)\\,(t-17.600)/0.050\\,if(lt(t\\,17.570)\\,1\\,if(lt(t\\,17.620)\\,(17.620-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='to':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,17.641)\\,0\\,if(lt(t\\,17.691)\\,(t-17.641)/0.050\\,if(lt(t\\,17.692)\\,1\\,if(lt(t\\,17.742)\\,(17.742-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='son':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,17.843)\\,0\\,if(lt(t\\,17.893)\\,(t-17.843)/0.050\\,if(lt(t\\,17.975)\\,1\\,if(lt(t\\,18.025)\\,(18.025-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='de':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,18.167)\\,0\\,if(lt(t\\,18.217)\\,(t-18.167)/0.050\\,if(lt(t\\,18.239)\\,1\\,if(lt(t\\,18.289)\\,(18.289-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Grup√≥n.':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,18.309)\\,0\\,if(lt(t\\,18.359)\\,(t-18.309)/0.050\\,if(lt(t\\,19.170)\\,1\\,if(lt(t\\,19.220)\\,(19.220-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Soy':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,19.200)\\,0\\,if(lt(t\\,19.250)\\,(t-19.200)/0.050\\,if(lt(t\\,19.494)\\,1\\,if(lt(t\\,19.544)\\,(19.544-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Ken':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,19.605)\\,0\\,if(lt(t\\,19.655)\\,(t-19.605)/0.050\\,if(lt(t\\,19.616)\\,1\\,if(lt(t\\,19.666)\\,(19.666-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Bawekel':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,19.686)\\,0\\,if(lt(t\\,19.736)\\,(t-19.686)/0.050\\,if(lt(t\\,20.203)\\,1\\,if(lt(t\\,20.253)\\,(20.253-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='pa':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,20.273)\\,0\\,if(lt(t\\,20.323)\\,(t-20.273)/0.050\\,if(lt(t\\,20.304)\\,1\\,if(lt(t\\,20.354)\\,(20.354-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='cuando':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,20.496)\\,0\\,if(lt(t\\,20.546)\\,(t-20.496)/0.050\\,if(lt(t\\,20.729)\\,1\\,if(lt(t\\,20.779)\\,(20.779-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='jugaba':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,20.961)\\,0\\,if(lt(t\\,21.011)\\,(t-20.961)/0.050\\,if(lt(t\\,21.397)\\,1\\,if(lt(t\\,21.447)\\,(21.447-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='en':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,21.488)\\,0\\,if(lt(t\\,21.538)\\,(t-21.488)/0.050\\,if(lt(t\\,21.701)\\,1\\,if(lt(t\\,21.751)\\,(21.751-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Newcon.':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,21.913)\\,0\\,if(lt(t\\,21.963)\\,(t-21.913)/0.050\\,if(lt(t\\,22.490)\\,1\\,if(lt(t\\,22.540)\\,(22.540-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Siempre':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,22.520)\\,0\\,if(lt(t\\,22.570)\\,(t-22.520)/0.050\\,if(lt(t\\,22.855)\\,1\\,if(lt(t\\,22.905)\\,(22.905-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='estoy':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,22.925)\\,0\\,if(lt(t\\,22.975)\\,(t-22.925)/0.050\\,if(lt(t\\,23.057)\\,1\\,if(lt(t\\,23.107)\\,(23.107-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='tirado':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,23.188)\\,0\\,if(lt(t\\,23.238)\\,(t-23.188)/0.050\\,if(lt(t\\,23.563)\\,1\\,if(lt(t\\,23.613)\\,(23.613-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='en':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,23.634)\\,0\\,if(lt(t\\,23.684)\\,(t-23.634)/0.050\\,if(lt(t\\,23.725)\\,1\\,if(lt(t\\,23.775)\\,(23.775-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='el':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,23.796)\\,0\\,if(lt(t\\,23.846)\\,(t-23.796)/0.050\\,if(lt(t\\,23.968)\\,1\\,if(lt(t\\,24.018)\\,(24.018-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='verde':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,24.039)\\,0\\,if(lt(t\\,24.089)\\,(t-24.039)/0.050\\,if(lt(t\\,24.231)\\,1\\,if(lt(t\\,24.281)\\,(24.281-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='como':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,24.403)\\,0\\,if(lt(t\\,24.453)\\,(t-24.403)/0.050\\,if(lt(t\\,24.555)\\,1\\,if(lt(t\\,24.605)\\,(24.605-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='un':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,24.646)\\,0\\,if(lt(t\\,24.696)\\,(t-24.646)/0.050\\,if(lt(t\\,24.657)\\,1\\,if(lt(t\\,24.707)\\,(24.707-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='crut√≥n.':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,25.577)\\,0\\,if(lt(t\\,25.627)\\,(t-25.577)/0.050\\,if(lt(t\\,25.770)\\,1\\,if(lt(t\\,25.820)\\,(25.820-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Tengo':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,25.800)\\,0\\,if(lt(t\\,25.850)\\,(t-25.800)/0.050\\,if(lt(t\\,26.113)\\,1\\,if(lt(t\\,26.163)\\,(26.163-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='la':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,26.244)\\,0\\,if(lt(t\\,26.294)\\,(t-26.244)/0.050\\,if(lt(t\\,26.396)\\,1\\,if(lt(t\\,26.446)\\,(26.446-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='grasa':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,26.466)\\,0\\,if(lt(t\\,26.516)\\,(t-26.466)/0.050\\,if(lt(t\\,26.901)\\,1\\,if(lt(t\\,26.951)\\,(26.951-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='que':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,26.971)\\,0\\,if(lt(t\\,27.021)\\,(t-26.971)/0.050\\,if(lt(t\\,26.982)\\,1\\,if(lt(t\\,27.032)\\,(27.032-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='no':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,27.052)\\,0\\,if(lt(t\\,27.102)\\,(t-27.052)/0.050\\,if(lt(t\\,27.103)\\,1\\,if(lt(t\\,27.153)\\,(27.153-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='se':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,27.214)\\,0\\,if(lt(t\\,27.264)\\,(t-27.214)/0.050\\,if(lt(t\\,27.265)\\,1\\,if(lt(t\\,27.315)\\,(27.315-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='saca':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,27.416)\\,0\\,if(lt(t\\,27.466)\\,(t-27.416)/0.050\\,if(lt(t\\,27.668)\\,1\\,if(lt(t\\,27.718)\\,(27.718-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='con':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,27.840)\\,0\\,if(lt(t\\,27.890)\\,(t-27.840)/0.050\\,if(lt(t\\,27.931)\\,1\\,if(lt(t\\,27.981)\\,(27.981-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='Googan':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,28.102)\\,0\\,if(lt(t\\,28.152)\\,(t-28.102)/0.050\\,if(lt(t\\,28.719)\\,1\\,if(lt(t\\,28.769)\\,(28.769-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='y':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,29.152)\\,0\\,if(lt(t\\,29.202)\\,(t-29.152)/0.050\\,if(lt(t\\,29.163)\\,1\\,if(lt(t\\,29.213)\\,(29.213-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='la':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,29.334)\\,0\\,if(lt(t\\,29.384)\\,(t-29.334)/0.050\\,if(lt(t\\,29.446)\\,1\\,if(lt(t\\,29.496)\\,(29.496-t)/0.050\\,0))))',drawtext=fontfile='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf':text='cabeza,':fontcolor=white:fontsize=60:x=(w-text_w)/2:y=(h-text_h)/2:alpha='if(lt(t\\,29.516)\\,0\\,if(lt(t\\,29.566)\\,(t-29.516)/0.050\\,if(lt(t\\,29.930)\\,1\\,if(lt(t\\,29.980)\\,(29.980-t)/0.050\\,0))))'\n",
            "Creando video base...\n",
            "Ejecutando ffmpeg para generar el video final...\n",
            "‚úÖ Video generado con √©xito: video_final.mp4\n"
          ]
        }
      ],
      "source": [
        "# Instalar ffmpeg (si no estuviera instalado, en Colab generalmente ya viene)\n",
        "\n",
        "\n",
        "import json\n",
        "import subprocess\n",
        "\n",
        "def obtener_duracion_audio(audio_path):\n",
        "    \"\"\"Obtiene la duraci√≥n del audio usando ffprobe.\"\"\"\n",
        "    result = subprocess.run(\n",
        "        [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"json\", audio_path],\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "    duracion = float(json.loads(result.stdout)[\"format\"][\"duration\"])\n",
        "    return duracion\n",
        "\n",
        "def limpiar_texto(texto):\n",
        "            texto = re.sub(r\"[^\\w\\s√°√©√≠√≥√∫√º√±√Å√â√ç√ì√ö√ú√ë.,;:¬°!¬ø?\\\"'()\\-\\[\\]{}<>‚Ä¶‚Äì‚Äî¬∞%‚Ç¨$@#&+=*/\\\\]\", \"\", texto)\n",
        "            texto = texto.replace(\":\", \"\")   # Escapar los dos puntos\n",
        "            texto = texto.replace(\"'\", \"\")   # Escapar comillas simples\n",
        "            texto = texto.replace('\"', '')   # Escapar comillas dobles\n",
        "            texto = texto.replace(\"\\\\\", \"\") # Escapar backslashes\n",
        "            return texto\n",
        "\n",
        "def generar_filtros_drawtext(frases, font_path=\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"):\n",
        "    \"\"\"\n",
        "    Genera un filtro drawtext para cada palabra (con su tiempo de inicio y fin),\n",
        "    aplicando un efecto de fade in/out al mostrar la palabra.\n",
        "    \"\"\"\n",
        "    filtros = []\n",
        "    for f in frases:\n",
        "        # Procesar y limpiar el texto, luego envolvemos el texto entre comillas simples\n",
        "        texto = limpiar_texto(f.get(\"word\", \"\"))\n",
        "        texto = f\"'{texto}'\"\n",
        "\n",
        "        start = float(f[\"start\"])\n",
        "        end = float(f[\"end\"])\n",
        "        fade_dur = 0.05  # Duraci√≥n del fade in/out, ajustable\n",
        "\n",
        "        fade_in_end = start + fade_dur\n",
        "        fade_out_start = end - fade_dur\n",
        "\n",
        "        # Generar la expresi√≥n alpha\n",
        "        alpha_expr = (\n",
        "            f\"if(lt(t,{start:.3f}),0,\"\n",
        "            f\"if(lt(t,{fade_in_end:.3f}),(t-{start:.3f})/{fade_dur:.3f},\"\n",
        "            f\"if(lt(t,{fade_out_start:.3f}),1,\"\n",
        "            f\"if(lt(t,{end:.3f}),({end:.3f}-t)/{fade_dur:.3f},0))))\"\n",
        "        )\n",
        "        # Escapar las comas dentro de la expresi√≥n para que no se interpreten como separador de filtros\n",
        "        alpha_expr = alpha_expr.replace(\",\", r\"\\,\")\n",
        "\n",
        "        filtro = (\n",
        "            f\"drawtext=fontfile='{font_path}':\"\n",
        "            f\"text={texto}:\"\n",
        "            f\"fontcolor=white:fontsize=60:\"\n",
        "            f\"x=(w-text_w)/2:\"\n",
        "            f\"y=(h-text_h)/2:\"\n",
        "            f\"alpha='{alpha_expr}'\"\n",
        "        )\n",
        "        filtros.append(filtro)\n",
        "    # Unir los filtros drawtext con comas para aplicarlos sobre el mismo video.\n",
        "    filtro_completo = \",\".join(filtros)\n",
        "    return filtro_completo\n",
        "\n",
        "def main():\n",
        "    # Definir rutas de entrada/salida\n",
        "    audio = \"audio.mp3\"\n",
        "    json_file = \"audio.aligned.json\"\n",
        "    output = \"video_final.mp4\"\n",
        "\n",
        "    # Obtener la duraci√≥n del audio para crear el video base\n",
        "    duracion_audio = obtener_duracion_audio(audio)\n",
        "    # Se a√±ade 1 segundo extra a la duraci√≥n del video base (ajustable)\n",
        "    duracion_video = duracion_audio + 1\n",
        "\n",
        "    # Leer el archivo JSON con la alineaci√≥n de las palabras\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        frases = json.load(f)\n",
        "\n",
        "    # Generar el filtro de drawtext\n",
        "    drawtext_filter = generar_filtros_drawtext(frases)\n",
        "    print(\"Filtro drawtext generado:\\n\", drawtext_filter)\n",
        "\n",
        "    # Crear un video base negro con la duraci√≥n calculada, resoluci√≥n 1280x720 a 30fps\n",
        "    comando_crear_base = [\n",
        "        \"ffmpeg\",\n",
        "        \"-y\",  # Sobrescribir si existe\n",
        "        \"-f\", \"lavfi\",\n",
        "        \"-i\", f\"color=size=1280x720:duration={duracion_video}:rate=30:color=black\",\n",
        "        \"base.mp4\"\n",
        "    ]\n",
        "\n",
        "    print(\"Creando video base...\")\n",
        "    resultado = subprocess.run(comando_crear_base, stderr=subprocess.PIPE, text=True)\n",
        "    if resultado.returncode != 0:\n",
        "        print(\"Error al crear el video base:\", resultado.stderr)\n",
        "        return\n",
        "\n",
        "    # Combinar video base, audio y aplicar el filtro de texto\n",
        "    comando_ffmpeg = [\n",
        "        \"ffmpeg\",\n",
        "        \"-y\",  # Sobrescribir salida\n",
        "        \"-i\", \"base.mp4\",\n",
        "        \"-i\", audio,\n",
        "        \"-vf\", drawtext_filter,\n",
        "        \"-c:v\", \"libx264\",\n",
        "        \"-tune\", \"stillimage\",\n",
        "        \"-c:a\", \"aac\",\n",
        "        \"-shortest\",\n",
        "        output\n",
        "    ]\n",
        "\n",
        "    print(\"Ejecutando ffmpeg para generar el video final...\")\n",
        "    resultado = subprocess.run(comando_ffmpeg, stderr=subprocess.PIPE, text=True)\n",
        "    if resultado.returncode != 0:\n",
        "        print(\"‚ùå Error al generar el video:\")\n",
        "        print(resultado.stderr)\n",
        "    else:\n",
        "        print(\"‚úÖ Video generado con √©xito:\", output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HXN4iqYyWDsw",
        "H2I7k0VH6sIW",
        "RmrKwuk6C5lU",
        "a4RQmPokDAbk"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
